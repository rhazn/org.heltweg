[{"content":"Our paper \u0026ldquo;Challenges to Open Collaborative Data Engineering\u0026rdquo; got accepted to the Hawaii International Conference on System Sciences 2023 (HICSS 56).\nAbstract Open data is data that can be used, modified, and passed on, for free, similar to open-source software. Unlike open-source, however, there is little collaboration in open data engineering. We perform a systematic literature review of collaboration systems in open data, specifically for data engineering by users, taking place after data has been made available as open data. The results show that open data users perform a wide range of activities to acquire, understand, process and maintain data for their projects without established best practices or standardized tools for open collaboration. We identify and discuss technical, community, and process challenges to collaboration in data engineering for open data.\nDownload Paper local\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/challenges-to-open-collaborative-data-engineering/","summary":"Our paper \u0026ldquo;Challenges to Open Collaborative Data Engineering\u0026rdquo; got accepted to the Hawaii International Conference on System Sciences 2023 (HICSS 56).\nAbstract Open data is data that can be used, modified, and passed on, for free, similar to open-source software. Unlike open-source, however, there is little collaboration in open data engineering. We perform a systematic literature review of collaboration systems in open data, specifically for data engineering by users, taking place after data has been made available as open data.","title":"Challenges to Open Collaborative Data Engineering"},{"content":"At the start of July, I visited the Softwarecampus Kickoff Event. The Softwarecampus is a project targeting self-described \u0026ldquo;EntrepreNerds\u0026rdquo; and sponsoring research projects with an industry partner with up to 100k‚Ç¨. Having been to a few ice-breaker events with fellow nerds I anticipated an awkward day but I was pleasantly surprised. In the hope of being pleasantly surprised again in the future, I wanted to share some ways the Softwarecampus team made the event stand out to me.\nThe environment: The kickoff event took place at the Forum Digitale Technologien in Berlin. The room we used was a large, open space and included a small exhibition of other research projects. Together with the relaxed pacing of the event, this provided interesting things to talk about and felt less like a forced getting to know people and more like an exhibition tour.\nShort, random group chats: This was the more classically-awkward part of the event but it was still well done. We were assigned to small (3-5 person) groups to present and talk about our projects to the others in about five minutes. The groups were created by gathering around home towns first and larger research areas later.\nCollaborative comic writing: This was the highlight of the event for me. With our last group (organized by research area so everyone roughly knows what the other people are doing), we were asked to choose a hero and create a three-panel comic/story that included references to our projects and how they are used to overcome challenges. We chose Alice in Wonderland and built a beautifully absurd story about how Alice has to find good open data (my project) to convince the sexist Mad Hatter and his bunnies that they are wrong and she should be let into Wonderland. While we talked about our story, artists walked from group to group and drew the comic panels from descriptions (edited to add a link to their business: Miss Vizzz). Because we had to try to find a way to fit references to all our projects into the story, we had to discuss what we were doing in detail but always with the absurd background of helping Alice into Wonderland. Finally, we had to explain our story (and by extension our projects) to the artists and present our story to the group. All of this made for a fun activity that, without feeling forced, communicated a lot of info about everyone\u0026rsquo;s goals.\nIn the end, we voted on who had the best story and presentation, we did not win (which, for the record I heavily disagree with and is a scandal) and went on to have a nice dinner. So, thank you Softwarecampus-Team (Susanne \u0026amp; Stefan) and other people planning kickoff events for nerds: Consider hiring artists and drawing some comics.\nKickoff Participants\n","permalink":"https://heltweg.org/posts/swc-kickoff/","summary":"At the start of July, I visited the Softwarecampus Kickoff Event. The Softwarecampus is a project targeting self-described \u0026ldquo;EntrepreNerds\u0026rdquo; and sponsoring research projects with an industry partner with up to 100k‚Ç¨. Having been to a few ice-breaker events with fellow nerds I anticipated an awkward day but I was pleasantly surprised. In the hope of being pleasantly surprised again in the future, I wanted to share some ways the Softwarecampus team made the event stand out to me.","title":"Softwarecampus 2022 - How to run a kickoff event for nerds"},{"content":" \u0026ldquo;There are only two hard things in Computer Science: cache invalidation and naming things.\u0026rdquo;\n - Phil Karlton\nAngularJS was released in 2010 and revolutionized modern frontend development. In 2016, the AngularJS team published a new framework, written in TypeScript and incompatible with AngularJS. They also made the baffling choice to call this framework Angular 2.\nMayhem ensued, confused developers talked to each other about incompatible frameworks. The excellent community documentation AngularJS had built in the form of blogs and StackOverflow answers became an active hindrance for people trying to learn Angular. Undeterred by this, the Angular team doubled down and kept releasing incompatible framework versions, only distinguished by a number.\nFive years later, the team announced that AngularJS would be discontinued. Immediately they needed to clarify that they would not discontinue Angular but only AngularJS.\nAngular clearing up confusion, five years later\nEven with the best documentation, users are going to google for information. They are going to read blogs, ask on StackOverflow and copy answers. So to make it easy on them, please:\n Use unique names for major versions (\u0026ldquo;Android KitKat\u0026rdquo; instead of \u0026ldquo;Android 4.4\u0026rdquo;). They are easier to include in searches. Use error codes (like \u0026ldquo;Error 34\u0026rdquo;) or slugs (like \u0026ldquo;ERROR_SOME_NAME\u0026rdquo;) in addition to localized, readable messages. Unique strings enable users with different languages than English to contribute. As a user, use Software in English. It makes it easier to google for errors ;).  About Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/chose-names-for-google-not-people/","summary":"\u0026ldquo;There are only two hard things in Computer Science: cache invalidation and naming things.\u0026rdquo;\n - Phil Karlton\nAngularJS was released in 2010 and revolutionized modern frontend development. In 2016, the AngularJS team published a new framework, written in TypeScript and incompatible with AngularJS. They also made the baffling choice to call this framework Angular 2.\nMayhem ensued, confused developers talked to each other about incompatible frameworks. The excellent community documentation AngularJS had built in the form of blogs and StackOverflow answers became an active hindrance for people trying to learn Angular.","title":"Choose names for Google, not people"},{"content":"It is a beautiful rite of passage for a bright-eyed junior developer to join a team, take some tasks full of enthusiasm, and have the life and joy sucked out of them one sprint at a time. Soon enough, they sit in planning meetings, miserably complaining, accusingly asking who wrote that shit. Their transformation to a full team member is complete. They have become one of us.\nI was once that bright-eyed junior developer. Many encounters with PHP4 later could no longer look forward to creating new features. Instead, I looked back and complained about old ones. Trashing legacy software is fun. It creates camaraderie. Who wrote this? What were they thinking? Looking at the commit log showed names that meant nothing to me. Ghosts that moved on long ago, leaving nothing but their shit code.\nOne day, I was pair programming with my friend Torben. Torben was a senior developer who introduced me to the team months earlier. When I found some weird code, I followed the tradition. Who was dumb enough to write this? I opened the commit log, and for the first time, I recognized a name: \u0026ldquo;Torben.\u0026rdquo;\nSince then, I remind myself that legacy software is written by people like me. Torben had constraints I knew nothing about. He worried about deadlines long past. Torben had learned a lot since then. Development workflows had evolved, infrastructure had gotten better.\nAnd to all the junior developers who have complained to my face about my trash code: I forgive you, I understand.\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/who-wrote-this-shit/","summary":"It is a beautiful rite of passage for a bright-eyed junior developer to join a team, take some tasks full of enthusiasm, and have the life and joy sucked out of them one sprint at a time. Soon enough, they sit in planning meetings, miserably complaining, accusingly asking who wrote that shit. Their transformation to a full team member is complete. They have become one of us.\nI was once that bright-eyed junior developer.","title":"Who wrote this shit?"},{"content":"Abstract Belief change research investigates how agents adapt their knowledge with potentially conflicting information. A common formalization is by epistemic states, abstract entities often represented by faithful preorders. Operators describe how epistemic states change with new evidence and are classified by which postulates they satisfy. Different approaches have been suggested for the problem of iterated belief change. Recent work introduces uniform revision that revises an agent\u0026rsquo;s beliefs based on one static total preorder, therefore lowering representational costs.\nIn this thesis, an extended epistemic state approach is introduced, based on an agent deterministically switching between total preorders. Challenges for implementations in the area of iterated belief change, like textual representation of total preorders, are pointed out and solutions developed. A tool for the automated certification of postulates for iterated belief change, called Coeus, is implemented for the new operator. Finally, the developed software is evaluated empirically. Coeus is publicly available, and most of its code is open-source.\nDownload Master thesis local\nMaster thesis colloquium slides\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/master-thesis/","summary":"Abstract Belief change research investigates how agents adapt their knowledge with potentially conflicting information. A common formalization is by epistemic states, abstract entities often represented by faithful preorders. Operators describe how epistemic states change with new evidence and are classified by which postulates they satisfy. Different approaches have been suggested for the problem of iterated belief change. Recent work introduces uniform revision that revises an agent\u0026rsquo;s beliefs based on one static total preorder, therefore lowering representational costs.","title":"Master Thesis: Implementing a Structured Approach to Belief Revision by Deterministic Switching Between Total Preorders"},{"content":"Note: An extended version of this paper has been published at the 7th Workshop on Formal and Cognitive Reasoning, you can find it here.\nOur paper \u0026ldquo;Certification of Iterated Belief Changes via Model Checking and its Implementation\u0026rdquo; got accepted to the 19th International Workshop on Non-Monotonic Reasoning (NMR-2021) at the 18th International Conference on Principles of Knowledge Representation and Reasoning (KR 2021). During the workshop I held a short presentation of the results. You can find both the paper as well as the presentation slides here.\nAbstract Iterated belief change investigates principles for changes on epistemic states and their representational groundings. A common realisation of epistemic states are total preorders over possible worlds. In this paper, we consider the problem of certifying whether an operator over total preorders satisfies a given postulate. We introduce the first-order fragment FOTPC for expressing belief change postulates and present a way to encode information on changes into an FOTPC-structure. As a result, the question of whether a belief change fulfils a postulate becomes a model checking problem. We present Alchourron, an implementation of our approach, consisting of an extensive Java library, and also of a web interface, which suits didactic purposes and experimental studies.\nDownload NMR-2021 Paper local\nNMR-2021 Workshop Proceedings\nNMR-2021 Presentation Slides\nWorkshop Presentation Video    Video Link\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/certification-of-iterated-belief-changes-via-model-checking-and-its-implementation/","summary":"Note: An extended version of this paper has been published at the 7th Workshop on Formal and Cognitive Reasoning, you can find it here.\nOur paper \u0026ldquo;Certification of Iterated Belief Changes via Model Checking and its Implementation\u0026rdquo; got accepted to the 19th International Workshop on Non-Monotonic Reasoning (NMR-2021) at the 18th International Conference on Principles of Knowledge Representation and Reasoning (KR 2021). During the workshop I held a short presentation of the results.","title":"Certification of Iterated Belief Changes via Model Checking and its Implementation"},{"content":"Our paper \u0026ldquo;On Using Model Checking for the Certification of Iterated Belief Changes\u0026rdquo; got accepted to the 7th Workshop on Formal and Cognitive Reasoning (FCR-2021) at the 44th German Conference on Artificial Intelligence (KI-2021). During the workshop I held a short presentation of the results. You can find both the paper as well as the presentation slides here.\nAbstract The theory of iterated belief change investigates how epistemic states are changed according to new beliefs. This is typically done by focussing on postulates that govern how epistemic states are changed. A common realisation of epistemic states are total preorders over possible worlds. In this paper, we consider the problem of certifying whether an operator over total preorders satisfies a given postulate. We introduce the first-order fragment FOTPC for expressing belief change postulates and present a way to encode information on changes into an FOTPC-structure. As a result, the question of whether a belief change fulfils a postulate becomes a model checking problem. We developed Alchourron, an implementation of our approach, consisting of an extensive Java library, and also of a web interface, which suits didactic purposes and experimental studies. For Alchourron, we also present an evaluation of the running time with respect to logical properties.\nDownload FCR-2021 Paper local\nFCR-2021 Paper from CEUR Workshop Proceedings\nFCR-2021 Presentation Slides\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/on-using-model-checking-for-the-certification-of-iterated-belief-changes/","summary":"Our paper \u0026ldquo;On Using Model Checking for the Certification of Iterated Belief Changes\u0026rdquo; got accepted to the 7th Workshop on Formal and Cognitive Reasoning (FCR-2021) at the 44th German Conference on Artificial Intelligence (KI-2021). During the workshop I held a short presentation of the results. You can find both the paper as well as the presentation slides here.\nAbstract The theory of iterated belief change investigates how epistemic states are changed according to new beliefs.","title":"On Using Model Checking for the Certification of Iterated Belief Changes"},{"content":"I created this synopsis of some ideas from the paper \u0026ldquo;How to Revise a Total Preorder\u0026rdquo; by Booth and Meyer during the seminar on \u0026ldquo;Representation and processing of uncertain knowledge with logic-based methods\u0026rdquo; at the University of Hagen.\nThe slides are from my final presentation of the topic (and might be more or less useless on their own).\nAbstract Adapting one‚Äôs world view in the light of new information is a central skill of intelligent agents. Total preorders are a common tool to model plausibility orderings over possible worlds in the research field of belief change. In their paper ‚ÄùHow to Revise a Total Preorder‚Äù, Booth and Meyer present an approach to revising preorders for iterated belief revision. Their operator is based on assigning abstract intervals of plausibility to worlds, depending on new evidence supporting them or not. This synopsis presents part of their work in tpo-revision operators and their properties with the help of an accompanying example and additional visualisation.\nDownload Seminar Paper\nPresentation Slides\nSource Code\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/judges-aliens-and-total-preorders/","summary":"I created this synopsis of some ideas from the paper \u0026ldquo;How to Revise a Total Preorder\u0026rdquo; by Booth and Meyer during the seminar on \u0026ldquo;Representation and processing of uncertain knowledge with logic-based methods\u0026rdquo; at the University of Hagen.\nThe slides are from my final presentation of the topic (and might be more or less useless on their own).\nAbstract Adapting one‚Äôs world view in the light of new information is a central skill of intelligent agents.","title":"Of judges, aliens and total preorders"},{"content":"\u0026ldquo;You\u0026rsquo;ll never forget your first dragon\u0026rdquo; used to be the promise of Tibia, a free 2D-MMO I played as a young teenager. I spend day after day playing Tibia, training skills with friends and exploring the world and still\u0026hellip; never got to kill a dragon.\nComing back With nostalgia rekindled by quickly burning out on WoW: Shadowlands I tried to check in my old account. Sadly, I did not only forget the password but also lost control of my email address. Tibia allows you to restore access by sending an actual letter to the registered address of the account though. I entered my parents address, waited two weeks and actually got access to my account back.\nSadly it seems to be frozen due to hackers using it :(. I had to write support to actually unblock it.\nA glimmer of hope\nWhile waiting for my account to be unblocked I went digging\u0026hellip; The account said it was created in 2010, that is definitely too late, I remember playing as a kid/teenager and now I am old.\nBut I found some references still to my old Tibia life (Ranarion used to be my character name):\n\u0026ldquo;I heard you die twice. Once when they bury you in the grave. And the second is the last time when someone mentions your name.\u0026rdquo; - Irvin D. Yalom\nI used to play with a guild called Valheru on Antica. I never was a member because the minimum level required was 50 and I never made it above 18. But they took me under their wings, let me train with them and took me on some raids. It was a nice time filled with late nights trying to make my sorcerer better at shielding and 120‚Ç¨ internet bills.\nA lot of emails and security questions later my account was officially back and I could play again. As with all modern things Tibia now has a premium account (which I bought to upgrade my character from a Sorcerer to a Master Sorcerer).\nMaster Sorcerer Rhazn\nAfter I satisfied my nostalgia I was content to just let my premium time run out and not come back. But then I thought - could I actually find a fitting end for my 10+ year Tibia journey? What about the promise CipSoft made to me?\nI asked around how and where a level 35 Master Sorcerer might be able to solo kill a dragon and found out that some of them spawn near the old dwarven city of Kazordoon. Apparently it is also very helpful to summon demon skeletons as blockers because they are immune to fire.\nArmed with new knowledge, 120 mana potions and my two trusty companion skeletons I took a deep breath and entered \u0026ldquo;Kazordoon Dragon Lair\u0026rdquo;. When I saw the dragon on my radar I targeted it and ran away while spamming \u0026ldquo;Ice Strike\u0026rdquo;. 10+ years brought to a head in one moment:\nThe beast is dead\nThe actual fight was easy and fast, my skeleton friends and ice magic slaughtered the poor dragon quickly and \u0026ldquo;Mana Shield\u0026rdquo; allowed my Sorcerer to never be in any danger.\nI ran back to the main city Thais to log out somewhere but figured\u0026hellip; why not see if the old place me and the Valheru guild used to train and life still is around?\nThe guildhall an officer called \u0026ldquo;Kitiara\u0026rdquo; rented was called \u0026ldquo;Halls of Adventurers\u0026rdquo;. Meeting Kitiara and advertising her tavern with a \u0026ldquo;global say\u0026rdquo; spell was what introduced me to Valheru originally so I figured it would be a fitting end.\nWhen I reached the hall and inspected it, I saw that not only did it still exist, Kitiara was still renting it. When I tried to enter my character got immediately teleported out of course - my character was long forgotten.\nI logged out one last time in front of the halls, a fitting end for my Tibia story - you never forget your first dragon.\nSleep now\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/how-to-kill-a-dragon/","summary":"\u0026ldquo;You\u0026rsquo;ll never forget your first dragon\u0026rdquo; used to be the promise of Tibia, a free 2D-MMO I played as a young teenager. I spend day after day playing Tibia, training skills with friends and exploring the world and still\u0026hellip; never got to kill a dragon.\nComing back With nostalgia rekindled by quickly burning out on WoW: Shadowlands I tried to check in my old account. Sadly, I did not only forget the password but also lost control of my email address.","title":"How to kill a dragon"},{"content":"Finding needles There has never been as much information easily accessible to anyone as right now. The ease of publishing your own writing leads to new problems: The question is no longer where do you find content about a topic but what content is good and worth your time?\nTo help you find the needle in the biggest haystack ever, here is my personal list of good content that influenced me.\nThe list \u0026ldquo;Things You Should Never Do\u0026rdquo; by Joel Spolsky One of the main things I have learned when going from a young software engineer to working professionally for years is the value of iteration. I\u0026rsquo;ve personally been burned by completely rewriting projects and ever since keep this article around to remind myself of that. Also of the pain of living through the javascript framework frontend wars.\nThings You Should Never Do, Part 1\n\u0026ldquo;Choose Boring Technology\u0026rdquo; by Dan McKinley Years ago I read a blog post titled \u0026ldquo;Why I write Java\u0026rdquo; that basically boiled down to the author writing Java and using established technologies to focus on the product and not the tech. The blog\u0026rsquo;s first comment was \u0026ldquo;So you write java because you are an old, boring guy\u0026rdquo;. Sadly, that gem of internet discussion seems to be lost to time. This article presents the same ideas of cautioning against new technology (but not being dogmatic about never using it) and as a fellow old, boring person now I can see myself in it.\nChoose Boring Technology\n\u0026ldquo;The Product-Minded Software Engineer\u0026rdquo; by Gergely Orosz Job identities are hard. Am I a software engineer that wants to build an amazing algorithm? Am I a \u0026ldquo;creator\u0026rdquo; that wants to build a product? Am I a manager that wants to build a team? If you struggle to pin down what you actually want to do, this article introduces yet another category to fit your life into.\nThe Product-Minded Software Engineer\n\u0026ldquo;Give it five minutes\u0026rdquo; by Jason Fried Jason Fried and anything Basecamp are an interesting source for thoughtful content on business, software engineering and as it turns out even life advice ;). This is a really short blogpost that reminds me to keep an open mind and be humble.\nGive it five minutes\n\u0026ldquo;Are Passions Serendipitously Discovered or Painstakingly Constructed?\u0026rdquo; by Cal Newport A short blog for people being lost in life. If you are unsure about your goal in life or why you have no passions, maybe this is something to give you ideas. Also it has a headline that literally is \u0026ldquo;Short Case Study #2: The Bored Programmer\u0026rdquo;. If that does not fit the audience of this article, nothing will.\nAre Passions Serendipitously Discovered or Painstakingly Constructed?\n\u0026ldquo;Function + Feeling\u0026rdquo; by Haraldur Thorleifsson This is a talk and not a blog but it fits the list. In a world focused on monetizing and optimizing everything, talking about predatory business models and the death of privacy this was a nice reminder that our work can have real, positive impact on people and it\u0026rsquo;s worth fighting for that.\nFunction + Feeling\n\u0026ldquo;Salary Negotiation: Make More Money, Be More Valued\u0026rdquo; and \u0026ldquo;Don\u0026rsquo;t Call Yourself A Programmer, And Other Career Advice\u0026rdquo; by Patrick McKenzie For software engineers just starting a career I think these blogs are an absolute must read to navigate the business side (not only of coding but for anything). Since reading these my opinions on the approach to working itself has changed quite a bit but I still consider them a solid into.\nSalary Negotiation: Make More Money, Be More Valued\nDon\u0026rsquo;t Call Yourself A Programmer, And Other Career Advice\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/wisdom-from-the-internet/","summary":"Finding needles There has never been as much information easily accessible to anyone as right now. The ease of publishing your own writing leads to new problems: The question is no longer where do you find content about a topic but what content is good and worth your time?\nTo help you find the needle in the biggest haystack ever, here is my personal list of good content that influenced me.","title":"Wisdom from the Internet, content that influenced how I think about software (and life)."},{"content":"The popularity of machine learning, data science and related disciplines is exploding and with it the amount of courses, books, block posts etc you are exposed to. I recently finished the relatively old but highly rated course Machine Learning by Stanford University on Coursera and wanted to take the chance to offer my review and notes I took.\nThe course Although the course is old enough to be referred to as \u0026ldquo;classic\u0026rdquo; by quite a few descriptions I have read it is timeless in the sense that most good introductions are. It covers concepts from tools in ML like supervised- or unsupervised learning, tips for their application with algorithm rating and debugging and much more. Most topics are covered very timeless with the theory and math behind them being the focus.\nCoursera offers video lectures, lecture notes (as pdf) and a short text summary for most of the 11 weeks of the course. Grading is done using short quizzes at the end of each topic as well as programming exercises in Octave or Mathlab. Forums are available to help with any questions and mentors are good at answering anything that comes up.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  The good The video lectures are really well done and the content seems excellent and very \u0026ldquo;grounded\u0026rdquo;. It is definitely not a course trying to cash in on the hype surrounding ML.\nThe programming exercises are solid and introduced me well to a different side of software development that is more focussed on solving complex mathematical problems than displaying a centered div.\nThe forums and additional resources prepared by the mentors are very good, in every case where I had a problem it was already solved by someone else asking it in the forums.\nIf you don\u0026rsquo;t want to get a certificate the course is completely free.\nThe bad There is a noticeable drop in quality in the later weeks. While the content stays excellent the written summaries disappear, sometimes obvious double takes that should have been edited are left in videos and programming exercises have a lot of pre-written code in their descriptions.\nSolving programming assignments in Octave: Probably due to the age of the course the setup of Octave is not friction free - in the version I used the \u0026ldquo;pause\u0026rdquo; function was broken which made all programming assignments hang at the first stop. It was relatively easy for me to debug and fix by overwriting the internal pause function but I\u0026rsquo;ve seen quite a few questions about Octave issues in the forum. In addition Octave seems to not be the primary choice in the ML community but since the course teaches concepts over concrete implementation that is fine by me.\nNotes I took a lot of notes during the course (more than 120 pages to be exact). They are mostly very close to the course material provided but sometimes rephrased and annotated with additional comments from me. In case they help anyone you can: Download them here\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/machine-learning-basics-machine-learning-by-stanford-university-review-and-notes/","summary":"The popularity of machine learning, data science and related disciplines is exploding and with it the amount of courses, books, block posts etc you are exposed to. I recently finished the relatively old but highly rated course Machine Learning by Stanford University on Coursera and wanted to take the chance to offer my review and notes I took.\nThe course Although the course is old enough to be referred to as \u0026ldquo;classic\u0026rdquo; by quite a few descriptions I have read it is timeless in the sense that most good introductions are.","title":"Machine learning basics: Machine Learning by Stanford University (Coursera) review and notes"},{"content":"A tweet in the database is worth two in the API Working with tweets from the twitter API probably means importing data into your own database - the standard API does not provide historical data (only the last seven days) and has various rate limits.\nSo regardless of the final goal in this blog we\u0026rsquo;ll explore importing tweets from the API into a database for future use. All done with NodeJS, written in Typescript and utilizing MongoDB as data store.\nBig numbers, big problems Once you authenticate with the API and pull in the first tweets (for example using the twitter module on npm) you will notice tweets contain ids as numbers and \u0026ldquo;id_str\u0026rdquo; which is the same id just as string:\n{ \u0026#34;created_at\u0026#34;: \u0026#34;Wed Oct 10 20:19:24 +0000 2018\u0026#34;, \u0026#34;id\u0026#34;: 1050118621198921728, \u0026#34;id_str\u0026#34;: \u0026#34;1050118621198921728\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;To make room for more expression, we will now count all emojis as equal‚Äîincluding those with gender‚Äç‚Äç‚Äç ‚Äç‚Äçand skin t‚Ä¶ https://t.co/MkGjXf9aXm\u0026#34;, \u0026#34;user\u0026#34;: {}, \u0026#34;entities\u0026#34;: {} } The reason for this is that some languages (Javascript being one of them) can not work with big numbers. For example JS numbers are internally 64-bit floats and only use the first 53 bits for the integer value. Javascript provides the static property Number.MAX_SAFE_INTEGER as 9007199254740991 which is smaller than the id in the example tweet already.\nTo work with tweet ids we need a way to handle bigger numbers and use the \u0026ldquo;id_str\u0026rdquo;. big.js provides that functionality and is used in all following code examples.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  Saving tweets Saving tweets in MongoDB is easy. Since we are using typescript we can rely on the excellent (Typegoose library)[https://github.com/typegoose/typegoose] to create models for tweets and interact with MongoDB:\nimport { prop, Typegoose, index } from \u0026#34;@hasezoey/typegoose\u0026#34;; @index({ \u0026#34;entities.user_mentions.screen_name\u0026#34;: 1 }) export class TwitterStatus extends Typegoose { @prop({ required: true, unique: true, index: true }) id_str!: string; @prop({ required: true }) full_text!: string; @prop({ required: true }) entities!: { user_mentions: { screen_name: string }[] } @prop({ required: true }) created_at!: string; } export const TwitterStatusModel = new TwitterStatus().getModelForClass(TwitterStatus, { schemaOptions: { strict: false } }); Notice I only defined some properties I wanted to use in this model \u0026amp; the index is also related to my use case. You might need to change those depending on the project.\nIf schemaOptions define strict as false (see the last line) typegoose saves the whole JSON of the tweet in MongoDB, not just defined fields.\nImport logic To optimize the amount of tweets you can crawl from the API in the limits twitter provides an excellent resource on using the since_id and max_id parameters correctly here: https://developer.twitter.com/en/docs/tweets/timelines/guides/working-with-timelines.\nIn summary this means:\n set the since_id to the highest tweet id your application has already imported defining a lower bound for the imported tweets set the max_id to the max_id from the last import and subtract 1 defining the upper bound import tweets while setting max_id to the lowest id in the returned list until no new ones are returned, moving the upper bound closer to the lower bound once no new tweets are returned set max_id to undefined to remove the upper bound for future imports  If you want to crawl all mentions for an account you can keep track of your crawl status with this model:\nimport { prop, Typegoose } from \u0026#34;@hasezoey/typegoose\u0026#34;; export class TwitterCrawlStatus extends Typegoose { @prop({ required: true, unique: true, lowercase: true, trim: true }) account!: string; @prop({ trim: true }) sinceId?: string; @prop({ trim: true }) maxId?: string; @prop({ trim: true }) overallMaxId?: string; } export const TwitterCrawlStatusModel = new TwitterCrawlStatus().getModelForClas(TwitterCrawlStatus); A basic algorithm without any safeguards against failing that uses that logic and imports all mentions for a specific account follows:\nwhile(true) { const twitterCrawlStatus = await TwitterCrawlStatusModel.findOne({ account: account }; if (!twitterCrawlStatus) { twitterCrawlStatus = await TwitterCrawlStatusModel.create({ account: account }); await twitterCrawlStatus.save(); } const tweets = await twitterService.getMentions( account, twitterCrawlStatus.sinceId ? Big(twitterCrawlStatus.sinceId) : undefined, twitterCrawlStatus.maxId ? Big(twitterCrawlStatus.maxId).minus(1) : undefined, ); if (tweets.length \u0026gt; 0) { await TwitterStatusModel.bulkWrite(tweets.map(tweet =\u0026gt; { return { updateOne: { filter: { id_str: tweet.id_str }, update: { $set: tweet }, upsert: true } } })); const lowestId = (getLowestId(tweets) as Big); const highestId = (getHighestId(tweets) as Big); twitterCrawlStatus.maxId = lowestId.toFixed(); if (!twitterCrawlStatus.overallMaxId || Big(twitterCrawlStatus.overallMaxId).lt(highestId)) { twitterCrawlStatus.overallMaxId = highestId.toFixed(); } } else { twitterCrawlStatus.sinceId = twitterCrawlStatus.overallMaxId; twitterCrawlStatus.maxId = undefined; } await twitterCrawlStatus.save(); if (tweets.length === 0) { break; } } The twitter service .freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  The twitter service itself is just a minimalist wrapper around the twitter npm module:\nimport * as Twitter from \u0026#34;twitter\u0026#34;; import { Status } from \u0026#34;twitter-d\u0026#34;; import Big from \u0026#34;big.js\u0026#34;; export class TwitterService { private client: Twitter; constructor( consumerKey: string, consumerSecret: string, bearerToken: string ) { this.client = new Twitter({ consumer_key: consumerKey, consumer_secret: consumerSecret, bearer_token: bearerToken }); } public async getMentions( account: string, sinceId?: Big | undefined, maxId?: Big | undefined ): Promise\u0026lt;Status[]\u0026gt; { return await this.client.get(\u0026#34;search/tweets\u0026#34;, { q: `@${account}-filter:retweets`, result_type: \u0026#34;recent\u0026#34;, count: 100, include_entities: true, tweet_mode: \u0026#34;extended\u0026#34;, since_id: sinceId ? sinceId.toFixed(0) : undefined, max_id: maxId ? maxId.toFixed(0) : undefined }).then(response =\u0026gt; { return response.statuses; }); } } About Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/import-tweets-with-nodejs-and-the-twitter-api/","summary":"A tweet in the database is worth two in the API Working with tweets from the twitter API probably means importing data into your own database - the standard API does not provide historical data (only the last seven days) and has various rate limits.\nSo regardless of the final goal in this blog we\u0026rsquo;ll explore importing tweets from the API into a database for future use. All done with NodeJS, written in Typescript and utilizing MongoDB as data store.","title":"Analyzing twitter: Import tweets with NodeJS and the twitter API"},{"content":"As the final step in this long series of blogposts we are going to deploy a simple webapp in a docker container to my personal cloud. For context here is the personal cloud setup with Traefik/Let\u0026rsquo;s Encrypt (Run a personal cloud with Traefik, Let\u0026rsquo;s encrypt and Zookeeper).\nIn previous blogposts I also described how I built the app (Build a PWA in docker).\nApp deployment The deployment runs the docker container. If you follow my personal cloud setup make sure to use more than one replica as the nature of preemtive VMs means one replica might randomly get shut down.\nNote that the image will be set and updated by gitlab ci as described here: (Deploy to google kubernetes engine using gitlab ci).\nkind: Deployment apiVersion: extensions/v1beta1 metadata: name: ???-app spec: replicas: 3 template: metadata: labels: app: ???-app spec: terminationGracePeriodSeconds: 60 containers: - name: ???-app image: \u0026#34;eu.gcr.io/???/app:latest\u0026#34; The service and traefik ingress apiVersion: v1 kind: Service metadata: name: ???-app spec: selector: app: ???-app ports: - name: web port: 80 targetPort: 80 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: ???-app annotations: kubernetes.io/ingress.class: traefik traefik.frontend.passHostHeader: \u0026#34;false\u0026#34; traefik.frontend.priority: \u0026#34;1\u0026#34; spec: rules: - host: app.???.com http: paths: - path: / backend: serviceName: ???-app servicePort: web .freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  Updating the traefik config Updating the traefik config is important so traefik requests a new HTTPS certificate for the app from Let\u0026rsquo;s encrypt. You will need to add this line to the traefik toml file that is described here (Run a personal cloud with Traefik, Let\u0026rsquo;s encrypt and Zookeeper):\n[[acme.domains]] main = \u0026#34;app.???.com\u0026#34; DNS Now you can just point the A record of your domain to the traefik external IP and the rest will automatically be handled by your personal cloud :).\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/deploy-an-app-into-your-personal-cloud/","summary":"As the final step in this long series of blogposts we are going to deploy a simple webapp in a docker container to my personal cloud. For context here is the personal cloud setup with Traefik/Let\u0026rsquo;s Encrypt (Run a personal cloud with Traefik, Let\u0026rsquo;s encrypt and Zookeeper).\nIn previous blogposts I also described how I built the app (Build a PWA in docker).\nApp deployment The deployment runs the docker container.","title":"Deploy an app into your personal cloud"},{"content":"In a previous blogpost I showed how I build and publish docker images on gitlab ci (Build a docker image on gitlab ci)\nMake sure to read that post first for an overview and permission setup.\nUpdate the kubernetes service with the new docker image You can easily set up a deploy step using google\u0026rsquo;s own cloud SDK docker images. Note the service account with the permissions to change the kubernetes setup is saved as \u0026ldquo;GCLOUD_K8S_KEY\u0026rdquo; variable here.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  This job changes the image of my deployment for the app. You will need to change the last line in the script to whatever change you want to make to your kubernetes setup on deploy.\ndeploy: stage: deploy image: google/cloud-sdk:257.0.0 script: - echo $GCLOUD_K8S_KEY | base64 -d \u0026gt; ${HOME}/gcloud-k8s-key.json - gcloud auth activate-service-account --key-file ${HOME}/gcloud-k8s-key.json - gcloud config set project personal-cloud-project-id - gcloud config set compute/zone your-compute-zone - gcloud container clusters get-credentials production - kubectl set image deployment/???-app ???-app=eu.gcr.io/docker-project-id/app:${CI_COMMIT_SHA} only: - master when: manual About Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/deploy-to-google-kubernetes-engine-using-gitlab-ci/","summary":"In a previous blogpost I showed how I build and publish docker images on gitlab ci (Build a docker image on gitlab ci)\nMake sure to read that post first for an overview and permission setup.\nUpdate the kubernetes service with the new docker image You can easily set up a deploy step using google\u0026rsquo;s own cloud SDK docker images. Note the service account with the permissions to change the kubernetes setup is saved as \u0026ldquo;GCLOUD_K8S_KEY\u0026rdquo; variable here.","title":"Deploy to google kubernetes engine using gitlab ci"},{"content":"With my personal cloud setup based on kubernetes done (you can read about it here: https://heltweg.org/posts/run-a-personal-cloud-with-traefik-lets-encrypt-and-zookeeper/) it is time to actually deploy the first project into it.\nThe easiest application to deploy is a pure client side single page application, packaged in a docker container with a webserver like nginx to deliver the files. Packaging the application into it\u0026rsquo;s own container allows us to build a standardized container that can be run locally for testing or deployed to docker swarm and kubernetes.\nSetting up and configuring our own HTTP server also allows for fine tuning of caching to achieve good lighthouse scores:\nBuilding in docker For this setup we build the app using docker. That way the app is always built with the same node version and can be consistently reproduced, regardless of installed software on the local computer.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  The project here is a react application based on create-react-app but it works similarly with any frontend framework:\nFROMnode:12.6.0 AS buildWORKDIR/COPY package.json package-lock.json tsconfig.json ./RUN npm ciCOPY ./src ./srcCOPY ./public ./publicRUN npm run build --prodConfiguring nginx For the nginx config I placed a config file into the project and checked it in. This config file is later on copied into the container that serves the SPA. To achieve good performance we\n enable gzip for HTML/CSS and JS files set up caching for any file for one year (because create-react-app builds new file names with each production build that invalidates the cache on deploy) disable the cache for the actual index.html file (since we need to make the browser request the newest files) Redirect any request to index.html so the SPA router can handle them  You can see the complete config file here:\nserver { listen 80; server_name _; gzip on; gzip_types text/html text/css application/javascript; root /var/www/; index index.html; # Force all paths to load either itself (js files) or go through index.html. location /index.html { try_files $uri /index.html; add_header Cache-Control \u0026quot;no-store, no-cache, must-revalidate\u0026quot;; } location / { try_files $uri /index.html; expires 1y; add_header Cache-Control \u0026quot;public\u0026quot;; } } Building the final container The end result will be a combination of a) building the SPA in docker in the \u0026ldquo;build\u0026rdquo; step and then setting up a container from the nginx image and copying the JS from the build step as well as the checked in nginx config described above.\nFinally we expose port 80 and start nginx to serve the files.\nFROMnode:12.6.0 AS buildWORKDIR/COPY package.json package-lock.json tsconfig.json ./RUN npm ciCOPY ./src ./srcCOPY ./public ./publicRUN npm run build --prodFROMnginx:1.16.1COPY --from=build /build /var/www/COPY ./k8s/config/nginx.conf /etc/nginx/conf.d/default.confEXPOSE80CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;]About Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/build-a-progressive-web-app-in-docker-with-nginx-to-deploy-to-kubernetes-or-docker-swarm/","summary":"With my personal cloud setup based on kubernetes done (you can read about it here: https://heltweg.org/posts/run-a-personal-cloud-with-traefik-lets-encrypt-and-zookeeper/) it is time to actually deploy the first project into it.\nThe easiest application to deploy is a pure client side single page application, packaged in a docker container with a webserver like nginx to deliver the files. Packaging the application into it\u0026rsquo;s own container allows us to build a standardized container that can be run locally for testing or deployed to docker swarm and kubernetes.","title":"Build a progressive web app in docker with nginx to deploy to kubernetes or docker swarm"},{"content":"Kubernetes ingress with Traefik As mentioned in my last blog post I want to focus on a provider neutral setup for my own cloud, using technology that is not bound to any cloud offering whenever possible.\nWhile google cloud offers load balanced HTTP ingress by default it is apparently very expensive in comparison to running small nodes and I have heard only good things about using Traefik for kubernetes ingress.\nFor setting up Traefik I followed Manuel\u0026rsquo;s excellent guide with minor modifications (you can find the final files at the end of the article.)\nHTTPs and Let\u0026rsquo;s encrypt Traefik has built-in support for automatically getting and renewing HTTPS certificates with Let\u0026rsquo;s Encrypt. As HTTPS is good practice and a requirement for HTTP2 and PWAs anyway I set it up using example configurations from the Traefik docs.\nBecause I was using just one node for Traefik I chose to go with the easy setup of a local acme.json file that stores the certificate while the node is running.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  GKE Preemptible nodes, your own chaos monkey To save costs I chose to use \u0026ldquo;Preemtible VMs\u0026rdquo; as nodes to power my kubernetes cluster on GKE. According to google\u0026rsquo;s docs: \u0026ldquo;Preemptible VMs are Google Compute Engine VM instances that last a maximum of 24 hours and provide no availability guarantees.\u0026rdquo; This means the nodes in my kubernetes cluster randomly go down and are never up more than 24h. While this obviously is not a smart decision for a production setup I have chosen to embrace it and consider the nodes going down my own \u0026ldquo;chaos monkey\u0026rdquo; that forces me to write resilient code.\nA concrete example I ran into: The Let\u0026rsquo;s encrypt production API has a rate limit of requesting 5 certificates for the same URL in a week. Because my initial naive setup did not save the certificate anywhere it got lost whenever my Traefik node was terminated. While Traefik regenerates the certificate without any issue on startup\u0026hellip; after five startups I hit my rate limit and was greeted by an insecure warning without certificate.\nShared K/V store for Traefik with Zookeeper Enter a shared Key/Value store for Traefik. Using one is required if you want to run Traefik in cluster mode anyway (and I like to think my setup is easily scalable). It also means I can store my generated certificate in the K/V store where it will no longer just disappear when Traefik restarts.\nSince I have previous experience with Zookeeper and the setup was relatively painless I went with it.\nAll Kubernetes yaml files for the setup Finally the meat of the blog post, my complete setup as yaml files you can directly deploy into your GKE cluster:\nSet up Zookeeper first From this excellent ressource: https://github.com/kow3ns/kubernetes-zookeeper/blob/master/manifests/README.md\napiVersion: v1 kind: Service metadata: name: zk-hs labels: app: zk spec: ports: - port: 2888 name: server - port: 3888 name: leader-election clusterIP: None selector: app: zk --- apiVersion: v1 kind: Service metadata: name: zk-cs labels: app: zk spec: ports: - port: 2181 name: client selector: app: zk --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: zk spec: serviceName: zk-hs replicas: 1 podManagementPolicy: Parallel updateStrategy: type: RollingUpdate template: metadata: labels: app: zk spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \u0026#34;app\u0026#34; operator: In values: - zk topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: kubernetes-zookeeper imagePullPolicy: Always image: \u0026#34;gcr.io/google_containers/kubernetes-zookeeper:1.0-3.4.10\u0026#34; resources: requests: memory: \u0026#34;200M\u0026#34; cpu: \u0026#34;0.3\u0026#34; ports: - containerPort: 2181 name: client - containerPort: 2888 name: server - containerPort: 3888 name: leader-election command: - sh - -c - \u0026#34;start-zookeeper \\ --servers=1 \\ --data_dir=/var/lib/zookeeper/data \\ --data_log_dir=/var/lib/zookeeper/data/log \\ --conf_dir=/opt/zookeeper/conf \\ --client_port=2181 \\ --election_port=3888 \\ --server_port=2888 \\ --tick_time=2000 \\ --init_limit=10 \\ --sync_limit=5 \\ --heap=512M \\ --max_client_cnxns=60 \\ --snap_retain_count=3 \\ --purge_interval=12 \\ --max_session_timeout=40000 \\ --min_session_timeout=4000 \\ --log_level=INFO\u0026#34; readinessProbe: exec: command: - sh - -c - \u0026#34;zookeeper-ready 2181\u0026#34; initialDelaySeconds: 10 timeoutSeconds: 5 livenessProbe: exec: command: - sh - -c - \u0026#34;zookeeper-ready 2181\u0026#34; initialDelaySeconds: 10 timeoutSeconds: 5 volumeMounts: - name: datadir mountPath: /var/lib/zookeeper securityContext: runAsUser: 1000 fsGroup: 1000 volumeClaimTemplates: - metadata: name: datadir spec: accessModes: [ \u0026#34;ReadWriteOnce\u0026#34; ] resources: requests: storage: 5Gi Permissions for Traefik # create Traefik cluster role kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress-controller rules: - apiGroups: - \u0026#34;\u0026#34; resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch --- # create Traefik service account kind: ServiceAccount apiVersion: v1 metadata: name: traefik-ingress-controller namespace: default --- # bind role with service account kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress-controller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress-controller subjects: - kind: ServiceAccount name: traefik-ingress-controller namespace: default Traefik config Note the configuration of zookeeper using the service address for the \u0026ldquo;client service\u0026rdquo; (cs) as well as the Let\u0026rsquo;s encrypt config here.\n# define Traefik configuration kind: ConfigMap apiVersion: v1 metadata: name: traefik-config data: traefik.toml: |# traefik.toml defaultEntryPoints = [\u0026#34;http\u0026#34;, \u0026#34;https\u0026#34;] [entryPoints] [entryPoints.http] address = \u0026#34;:80\u0026#34; [entryPoints.http.redirect] entryPoint = \u0026#34;https\u0026#34; [entryPoints.https] address = \u0026#34;:443\u0026#34; [entryPoints.https.tls] [zookeeper] endpoint = \u0026#34;zk-cs.default.svc.cluster.local:2181\u0026#34; watch = true prefix = \u0026#34;traefik\u0026#34; [acme] email = \u0026#34;your@email.com\u0026#34; storage = \u0026#34;traefik/acme/account\u0026#34; onHostRule = true caServer = \u0026#34;https://acme-v02.api.letsencrypt.org/directory\u0026#34; acmeLogging = true entryPoint = \u0026#34;https\u0026#34; [acme.httpChallenge] entryPoint = \u0026#34;http\u0026#34; [[acme.domains]] main = \u0026#34;your.domain.com\u0026#34; Deployment for Traefik I run just one replica in here to save costs in my dev setup but I\u0026rsquo;ve also scaled it up to three to test if it would stay up 100% of the time even with random nodes going down and everything works fine :).\n# declare Traefik deployment kind: Deployment apiVersion: extensions/v1beta1 metadata: name: traefik-ingress-controller spec: replicas: 1 template: metadata: labels: app: traefik-ingress-controller spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 volumes: - name: config configMap: name: traefik-config containers: - name: traefik image: \u0026#34;traefik:1.7.14\u0026#34; volumeMounts: - mountPath: \u0026#34;/etc/traefik/config\u0026#34; name: config args: - --configfile=/etc/traefik/config/traefik.toml - --kubernetes - --logLevel=INFO Traefik service # Declare Traefik ingress service kind: Service apiVersion: v1 metadata: name: traefik-ingress-controller spec: selector: app: traefik-ingress-controller ports: - port: 80 name: http - port: 443 name: tls type: LoadBalancer .freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  Final result The final workloads with traefik and zookeeper\nAnd the kubernetes ingresses (ignore the app I used as demo for this).\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/run-a-personal-cloud-with-traefik-lets-encrypt-and-zookeeper/","summary":"Kubernetes ingress with Traefik As mentioned in my last blog post I want to focus on a provider neutral setup for my own cloud, using technology that is not bound to any cloud offering whenever possible.\nWhile google cloud offers load balanced HTTP ingress by default it is apparently very expensive in comparison to running small nodes and I have heard only good things about using Traefik for kubernetes ingress.","title":"Run a personal Cloud with Traefik, Lets encrypt and Zookeeper"},{"content":"Why invest in a personal cloud It has never been easier to host your personal side projects. Tools like surge.sh or Heroku make it painless to run your code. And if all else fails the old reliable \u0026ldquo;drag and drop files to a ftp\u0026rdquo; is always there - so why invest time into setting up your own personal cloud with kubernetes?\nMy goal for technology is typically to find a setup that gets boring to work with because I know it well and can focus on delivering new functionality. For that a setup needs to be future proof (so it continues to work for a long time), generic (so I can use it for a wide range of applications and do not need to switch for every project) and not bound to any company or product.\nDocker \u0026amp; kubernetes Docker and Kubernetes check most of these boxes. Kubernetes has de-facto won the orchestration war for containerized applications and managed kubernetes offerings from all major cloud providers means there is no provider lock-in. As an open source project that is not bound to individual company or setup you retain flexibility. Lastly learning more about it is useful in any case - if you stop developing your side projects the devops knowledge you gained still looks good on a CV.\nA further important point that separates kubernetes from similar offerings is that you can 100% forget about hardware while still being free to use standard technology. That means you do not need to maintain a set of servers if you use a managed kubernetes offering (like you would need to with docker swarm) but you are still not locked into any provider (like you would be by using AWS Beanstalk, Firebase or Heroku).\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  Why not\u0026hellip;? My own personal journey has made me try out the following alternatives in the order they are written down here and I have abandoned them all.\n Own servers  You need to maintain and update your own servers. If you do it without automation you will forget what you did. The complexity and learning curve is close to kubernetes anyway. Instead of learning about deployments and stateful sets you will need to know about processes or package managers. Scaling is harder.   Services (e.g. Firebase)  Very easy to set up and use, probably advisable if you work on one or a few projects Using vendor specific tools (like firebase realtime database) locks you and the logic of your app into that vendor. What if they change their offering (price? functionality?) Services are the hammer that makes very problem look like a nail. Instead of picking the best technology for a job you will start trying to shoehorn your problems to be solved by what is available.   Docker Swarm  I really liked it, very close to kubernetes but considerably easier Sadly still forces you to manage your own servers to set up the swarm cluster, I could not find a \u0026ldquo;managed docker swarm\u0026rdquo; solution (if you know one, let me know!)    The value of infrastructure as code By choosing kubernetes you also commit to keeping your infrastructure in code which has a plethora of benefits:\n it automatically and correctly documents your infrastructure and any changes you made by reading git logs you can easily redeploy it on new providers or e.g. locally for development all your infrastructure is in one place so you don\u0026rsquo;t need to think about how each project solved a problem  Organizing your projects For my personal cloud I chose:\n A Google Cloud Kubernetes Engine Cluster as cloud  Traefik as ingress router to forward requests to my projects Zookeeper for shared state between Traefik nodes Let\u0026rsquo;s Encrypt to automatically set up HTTPS   Every project has it\u0026rsquo;s own Google Cloud Container Registry as a private docker repository Service accounts allow the GKE cloud to pull the docker images of individual projects from the respective repository Infrastructure descriptions for the generic GKE setup and services is in one place, infrastructure descriptions for the individual projects is in their respective code Deployment is handled with gitlab  Further reading  Read my blog post about the actual setup of this cloud: /posts/run-a-personal-cloud-with-traefik-lets-encrypt-and-zookeeper. Also read this helpful article: Traefik on a Google Kubernetes Engine Cluster managed by Terraform by Manuel Zapf  About Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/kubernetes-for-sideprojects-hardware-is-dead/","summary":"Why invest in a personal cloud It has never been easier to host your personal side projects. Tools like surge.sh or Heroku make it painless to run your code. And if all else fails the old reliable \u0026ldquo;drag and drop files to a ftp\u0026rdquo; is always there - so why invest time into setting up your own personal cloud with kubernetes?\nMy goal for technology is typically to find a setup that gets boring to work with because I know it well and can focus on delivering new functionality.","title":"Kubernetes for sideprojects: Hardware is dead"},{"content":"Entity-Systems for typescript based games For my latest game project Frozzen I want to explore how an external UI, build with Angular, would work for a browser based game. Since Angular is written in Typescript that means ideally the game should also use the same.\nI have used Artemis ODB as framework for a Java based game in the past and liked it a lot. Entity-Systems are much better introduced by any of the huge amount of articles out there (for example the classic on T=Machine but I feel they are especially well suited to Javascript/Typescript development.\nIf you work with a strict separation of logic into systems and data only into components there is a very natural way to serialize components, JSON. Whole levels can be expressed as an array of JSON data that is used to set up components. That is why I prefer a very basic but strict implementation like artemis over similar frameworks like PhaserJS.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  I started my development with artemists, a Typescript port of artemis by darkoverlordofdata. Unfortunately the code is a bit outdated and does not use import/export and can not be directly imported for newer Typescript versions (since it extends the built-in Array).\nWith darkoverlordofdata‚Äôs permission I did a quick update to the Typescript parts of the code only, adding import/export support and fixing the build for newer Typescript versions. You can find the updated version here. If you are looking for an example of that framework in action you can play an example level of Frozzen here.\nAbout Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/entity-systems-for-typescript-based-games/","summary":"Entity-Systems for typescript based games For my latest game project Frozzen I want to explore how an external UI, build with Angular, would work for a browser based game. Since Angular is written in Typescript that means ideally the game should also use the same.\nI have used Artemis ODB as framework for a Java based game in the past and liked it a lot. Entity-Systems are much better introduced by any of the huge amount of articles out there (for example the classic on T=Machine but I feel they are especially well suited to Javascript/Typescript development.","title":"Entity-Systems for typescript based games"},{"content":"Blog requirements I recently evaluated what how writing content and carving out a little personal space on the internet would look like for me and came up with a list of requirements:\n Own my content (No third party platforms as only distribution method. There was a time before medium and there will be a time after medium.) Easy to set up and maintain (I don\u0026rsquo;t want to set up and host databases or complicated CMS systems and when I come back to this in a month it should be easy to update.) Long term secure storage (By not hosting my content with a third party but in git I can easily back it up, keep old revisions and there is no worry of the hosting provider going down.)  All these requirements are solved by using a static site generator and keeping the original files versioned in git. When setting up some for of continuous integration (for example with gitlab) it should be reasonably easy to maintaining for a long time.\nI chose gohugo as a site generator due to the excellent setup article written by Fabian Gruber here: https://www.fabiangruber.de/posts/setup-and-deployment\nAutomated builds I set up an automated build using gitlab using the following gitlab-ci.yml:\nstages: - build build: image: monachus/hugo:v0.55.3 stage: build script: - hugo artifacts: paths: - public/ This uses a docker image for Hugo and builds the static page from the sources provided.\nContinuous delivery I chose firebase to host the website because I have previous experience with it. It is very easy to create and deploy a static website as well as wire it up with a HTTPS domain.\nAfter creating a new project in firebase you\u0026rsquo;ll need to get a token that allows gitlab to make deployments on your behalf:\nfirebase login:ci Set it up as a secret variable in gitlab called \u0026ldquo;FIREBASE_TOKEN\u0026rdquo;.\nTo add firebase to the gohugo project navigate to the directory in the CLI can call:\nfirebase init Armed with the token that allows gitlab to deploy in your name as well as a configured firebase project we can add the last step to the gitlab-ci file - deployment.\n.freelance { border: 1px var(--theme-color-foreground) solid; padding: 24px; margin: 24px; display: flex; flex-direction: column; align-items: center; } .freelance__button { background-color: var(--theme-color-background) !important; color: var(--theme-color-foreground) !important; background-color: red; padding: 1em 1.5em; text-decoration: none !important; display: block; max-width: 50%; text-align: center; margin: 1em; }  I am a freelancer and would love to help you! EMAIL ME üëã  You can see the full gitlab-ci.yml file here:\nstages: - build - deploy build: image: monachus/hugo:v0.55.3 stage: build script: - hugo artifacts: paths: - public/ deploy: image: devillex/docker-firebase:slim stage: deploy only: - master script: - firebase use \u0026lt;project-name\u0026gt; --token $FIREBASE_TOKEN - firebase deploy --only hosting -m \u0026#34;Pipe $CI_PIPELINE_ID Build $CI_BUILD_ID\u0026#34; --token $FIREBASE_TOKEN environment: name: production url: https://\u0026lt;project-name\u0026gt;.firebaseapp.com dependencies: - build About Me I love getting emails! Talk to me at philip@heltweg.org! ","permalink":"https://heltweg.org/posts/deploy-a-personal-blog-with-hugo-firebase-and-gitlab/","summary":"Blog requirements I recently evaluated what how writing content and carving out a little personal space on the internet would look like for me and came up with a list of requirements:\n Own my content (No third party platforms as only distribution method. There was a time before medium and there will be a time after medium.) Easy to set up and maintain (I don\u0026rsquo;t want to set up and host databases or complicated CMS systems and when I come back to this in a month it should be easy to update.","title":"Deploy a personal blog with Hugo, Firebase and Gitlab"}]